name: LLM Chatbot Augmented with Enterprise Data (Gov Edition)
description: |
  This AMP demonstrates how to use an open source pre-trained instruction-following LLM (Large Language Model) to build a Chatbot-like web application. The responses of the LLM are enhanced by giving it context from an internal knowledge base. This context is retrieved by using an open source Vector Database to do semantic search.
author: Cloudera Inc.
specification_version: 1.0
prototype_version: 1.0
date: "2023-04-22"

environment_variables:
  # EMBEDDING_MODEL_REPO:
  #   default: "sentence-transformers/all-mpnet-base-v2"
  #   description: "Embedding model used (repo name in HF)"
  #   required: true
  # EMBEDDING_MODEL_NAME:
  #   default: "all-mpnet-base-v2"
  #   description: "Embedding model name"
  #   required: true
  # LLM_MODEL_NAME:
  #   default: "mistralai/Mistral-7B-Instruct-v0.2"
  #   description: "LLM model used (repo name in HF)"
  #   required: true
  # COLLECTION_NAME:
  #   default: "cml-default"
  #   description: "Collection name for Vector DB"
  #   required: true
  PATH:
    default: "${PATH}:$HOME/cuda/bin:$HOME/cuda/nvvm"
    description: "Leave this value as is"
    required: true
  LD_LIBRARY_PATH:
    default: "${LD_LIBRARY_PATH}:$HOME/cuda/lib64:$HOME/cuda/nvvm/lib64:$HOME/cuda/nvvm"
    description: "Leave this value as is"
    required: true
  CUDA_HOME:
    default: "$HOME/cuda"
    description: "Leave this value as is"
    required: true

runtimes:
  - editor: PBJ Workbench
    kernel: Python 3.9
    edition: GovCloud

tasks:
  - type: run_session
    name: Deploy NVIDIA Toolkit
    script: 0_session-resource-validation/install-drivers.py
    short_summary: Deploy NVIDIA Toolkit
    kernel: python3
    cpu: 2
    memory: 16
    gpu: 1

  - type: run_session
    name: Install Dependencies
    script: 1_session-install-deps/install_dependencies.py
    short_summary: Install Dependencies
    kernel: python3
    cpu: 2
    memory: 16
    gpu: 1

  - type: run_session
    name: Install CUDA / Torch
    script: 1_session-install-deps/install-cuda.py
    short_summary: Install CUDA / Torch
    kernel: python3
    cpu: 2
    memory: 16
    gpu: 1

  - type: run_session
    name: Setup Chroma DB
    script: 1_session-install-deps/setup-chroma.py
    short_summary: Setup Chroma DB
    kernel: python3
    cpu: 2
    memory: 2

  - type: create_job
    name: Download Models
    entity_label: download_data_and_models
    script: 2_job-download-models/download_models.py
    arguments: None
    short_summary: Create job to download pre-trained models. 
    long_summary: Create job to download open source pre-trained models required by the LLM Chatbot application. All models are downloaded to a local directory. 
    cpu: 1
    memory: 4
    environment:
      TASK_TYPE: CREATE/RUN_JOB

  - type: run_job
    entity_label: download_data_and_models
    short_summary: Run job to download pre-trained models.

  - type: create_job
    name: Setup a Job for user to convert HTMLs to Text for loading to Vector DB
    entity_label: vectordb_insert
    script: 3_job-populate-vectordb/html-to-text.py
    arguments: None
    short_summary: Setup a Job for user to convert HTMLs to Text for loading to Vector DB
    cpu: 2
    memory: 8
    environment:
      TASK_TYPE: CREATE/RUN_JOB

  - type: create_job
    name: Populate Vector DB with documents embeddings
    entity_label: vectordb_insert
    script: 3_job-populate-vectordb/vectordb_insert.py
    arguments: None
    short_summary: Create job to populate Vector Database with document embeddings. 
    long_summary: Create job to launch Milvus Vector Database locally and insert embeddings for documents. Embeddings are generated by the locally running embeddings model.
    cpu: 1
    memory: 4
    environment:
      TASK_TYPE: CREATE/RUN_JOB

  - type: run_job
    entity_label: vectordb_insert
    short_summary: Populate Vector DB with documents embeddings
  
  - type: start_application
    name: CML LLM Chatbot
    subdomain: cmlllm
    script: 4_app/llm_rag_app.py
    short_summary: Start CML LLM Chatbot application
    long_summary: This application requires an available GPU to run the LLM model. Startup may be delayed if autoscaling is being performed or fail if GPU cannot be scheduled on this workspace. Please contact your administrator for GPU scheduling.
    cpu: 2
    memory: 16
    gpu: 1
    environment_variables:
      TASK_TYPE: START_APPLICATION
